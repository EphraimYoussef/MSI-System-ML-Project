{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T15:57:43.672393Z",
     "start_time": "2025-12-18T15:57:39.541333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D"
   ],
   "id": "2777a071c5694227",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T15:57:44.894845Z",
     "start_time": "2025-12-18T15:57:43.680469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "base_model = ResNet50(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False, # remove the last layer for having features only\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "model = Model(base_model.input, x)\n",
    "print(f\"Feature extractor output shape: {model.output_shape}\")"
   ],
   "id": "83772f4ac412409b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Feature extractor output shape: (None, 2048)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T15:57:44.917923Z",
     "start_time": "2025-12-18T15:57:44.914237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_image(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return preprocess_input(img)\n"
   ],
   "id": "3a7406f5f4b74535",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T15:57:44.929035Z",
     "start_time": "2025-12-18T15:57:44.923860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_features(dataset_path):\n",
    "    X, y = [], []\n",
    "    for cls in sorted(os.listdir(dataset_path)):\n",
    "        cls_path = os.path.join(dataset_path, cls)\n",
    "        if not os.path.isdir(cls_path):\n",
    "            continue\n",
    "\n",
    "        for img_name in tqdm(os.listdir(cls_path), desc=cls):\n",
    "            img = cv2.imread(os.path.join(cls_path, img_name))\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            img = preprocess_image(img)\n",
    "            feat = model.predict(img, verbose=0)\n",
    "            X.append(feat[0])   # 2048 features\n",
    "            y.append(cls)\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ],
   "id": "477fa2cac1c381eb",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T16:04:11.368444Z",
     "start_time": "2025-12-18T15:57:44.936932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nExtracting training features...\")\n",
    "X_train, y_train = extract_features(\"../data_split/train_aug\")\n",
    "\n",
    "print(\"\\nExtracting validation features...\")\n",
    "X_val, y_val = extract_features(\"../data_split/val\")\n",
    "\n",
    "print(\"\\nExtracting test features...\")\n",
    "X_test, y_test = extract_features(\"../data_split/test\")\n",
    "\n",
    "# Save all features\n",
    "os.makedirs(\"../features\", exist_ok=True)\n",
    "np.save(\"../features/X_train_cnn.npy\", X_train)\n",
    "np.save(\"../features/X_val_cnn.npy\", X_val)\n",
    "np.save(\"../features/X_test_cnn.npy\", X_test)\n",
    "np.save(\"../features/y_train.npy\", y_train)\n",
    "np.save(\"../features/y_val.npy\", y_val)\n",
    "np.save(\"../features/y_test.npy\", y_test)\n",
    "\n",
    "print(f\"\\n CNN feature extraction completed\")\n",
    "print(f\"   Train shape: {X_train.shape}\")\n",
    "print(f\"   Val shape:   {X_val.shape}\")\n",
    "print(f\"   Test shape:  {X_test.shape}\")"
   ],
   "id": "63b8e4d1a9f99032",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Extracting training features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cardboard: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 332/332 [00:51<00:00,  6.50it/s]\n",
      "glass: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 332/332 [00:48<00:00,  6.85it/s]\n",
      "metal: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 333/333 [00:51<00:00,  6.49it/s]\n",
      "paper: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 321/321 [00:49<00:00,  6.45it/s]\n",
      "plastic: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 323/323 [00:46<00:00,  6.88it/s]\n",
      "trash: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 339/339 [00:54<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Extracting validation features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cardboard: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:05<00:00,  7.46it/s]\n",
      "glass: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:07<00:00,  7.93it/s]\n",
      "metal: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49/49 [00:08<00:00,  6.09it/s]\n",
      "paper: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:10<00:00,  6.66it/s]\n",
      "plastic: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [00:08<00:00,  6.87it/s]\n",
      "trash: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:02<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Extracting test features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cardboard: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:05<00:00,  6.92it/s]\n",
      "glass: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:09<00:00,  6.44it/s]\n",
      "metal: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:06<00:00,  7.33it/s]\n",
      "paper: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:09<00:00,  7.88it/s]\n",
      "plastic: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [00:07<00:00,  7.26it/s]\n",
      "trash: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:02<00:00,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CNN feature extraction completed\n",
      "   Train shape: (1980, 2048)\n",
      "   Val shape:   (282, 2048)\n",
      "   Test shape:  (285, 2048)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
